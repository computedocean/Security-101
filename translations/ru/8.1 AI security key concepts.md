<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "66b61d96936cf25d20fcb411d4ce5227",
  "translation_date": "2025-09-03T22:45:23+00:00",
  "source_file": "8.1 AI security key concepts.md",
  "language_code": "ru"
}
-->
# Основные концепции безопасности ИИ

[![Смотреть видео](../../translated_images/8-1_placeholder.00bf95633da13ca44348bde620f848337ccbd7ae4022459eab1df7f37421ba4e.ru.png)](https://learn-video.azurefd.net/vod/player?id=ba44f5f7-9b47-462f-9aa5-13e2b71f4998)

## Чем безопасность ИИ отличается от традиционной кибербезопасности?

Обеспечение безопасности систем ИИ представляет собой уникальные вызовы по сравнению с традиционной кибербезопасностью, главным образом из-за особенностей обучения и процессов принятия решений в ИИ. Вот некоторые ключевые отличия:

-   **Целостность данных**: Системы ИИ в значительной степени зависят от данных для обучения. [Обеспечение целостности этих данных крайне важно, так как злоумышленники могут манипулировать данными, чтобы повлиять на поведение ИИ, что называется отравлением данных.
-   **Безопасность модели**: Модель принятия решений ИИ сама по себе может стать целью. [Злоумышленники могут попытаться провести обратную разработку модели или использовать её уязвимости для принятия неверных или вредоносных решений.
-   **Атаки с использованием противодействующих примеров**: Системы ИИ могут быть уязвимы к атакам с использованием противодействующих примеров, когда небольшие, часто незаметные изменения входных данных могут привести к ошибкам или неверным прогнозам.
-   **Безопасность инфраструктуры**: Хотя традиционная кибербезопасность также сосредоточена на защите инфраструктуры, системы ИИ могут иметь дополнительные уровни сложности, такие как облачные сервисы или специализированное оборудование, требующие особых мер безопасности.
-   **Этические аспекты**: Использование ИИ в безопасности поднимает вопросы этики, такие как конфиденциальность данных и возможность предвзятости в принятии решений, которые необходимо учитывать в стратегии безопасности.

В целом, обеспечение безопасности систем ИИ требует иного подхода, который учитывает уникальные аспекты технологии ИИ, включая защиту данных, моделей и процесса обучения, а также решение этических вопросов, связанных с внедрением ИИ.

Безопасность ИИ и традиционная кибербезопасность имеют много общего, но также отличаются из-за уникальных характеристик и возможностей систем искусственного интеллекта. Вот в чём заключаются различия:

- **Сложность угроз**: Системы ИИ добавляют новые уровни сложности в кибербезопасность. Традиционная кибербезопасность в основном имеет дело с угрозами, такими как вредоносное ПО, фишинговые атаки и сетевые вторжения. Однако системы ИИ могут быть уязвимы к атакам, таким как атаки с использованием противодействующих примеров, отравление данных и уклонение от модели, которые специально нацелены на алгоритмы машинного обучения.

- **Поверхность атаки**: Системы ИИ часто имеют более широкую поверхность атаки по сравнению с традиционными системами. Это связано с тем, что они зависят не только от программного обеспечения, но и от данных и моделей. Злоумышленники могут нацелиться на обучающие данные, манипулировать моделями или использовать уязвимости самих алгоритмов.

- **Адаптивность угроз**: Системы ИИ могут адаптироваться и учиться на основе окружающей среды, что делает их более уязвимыми к адаптивным и эволюционирующим угрозам. Традиционные меры кибербезопасности могут быть недостаточны для защиты от атак, которые постоянно меняются в зависимости от поведения системы ИИ.

- **Интерпретируемость и объяснимость**: Понять, почему система ИИ приняла то или иное решение, зачастую сложнее, чем в случае с традиционными программными системами. Этот недостаток интерпретируемости и объяснимости может затруднить эффективное обнаружение и предотвращение атак на системы ИИ.

- **Проблемы конфиденциальности данных**: Системы ИИ часто зависят от больших объёмов данных, что может создавать риски для конфиденциальности, если данные обрабатываются ненадлежащим образом. Традиционные меры кибербезопасности могут быть недостаточны для решения этих специфических проблем конфиденциальности данных в системах ИИ.

- **Соответствие нормативным требованиям**: Регуляторная среда для безопасности ИИ всё ещё развивается, и появляются конкретные нормы и стандарты, направленные на решение уникальных вызовов, связанных с системами ИИ. Традиционные рамки кибербезопасности могут потребовать расширения или адаптации для обеспечения соответствия этим новым требованиям.

- **Этические аспекты**: Безопасность ИИ включает не только защиту систем от злонамеренных атак, но и обеспечение того, чтобы системы ИИ использовались этично и ответственно. Это включает такие аспекты, как справедливость, прозрачность и подотчётность, которые могут быть менее заметны в традиционной кибербезопасности.

## Чем безопасность ИИ схожа с защитой традиционных ИТ-систем?

Обеспечение безопасности систем ИИ имеет несколько общих принципов с традиционной кибербезопасностью:

-   **Защита от угроз**: Как системы ИИ, так и традиционные системы нуждаются в защите от несанкционированного доступа, модификации данных, их уничтожения и других распространённых угроз.
-   **Управление уязвимостями**: Многие уязвимости, которые затрагивают традиционные системы, такие как ошибки в программном обеспечении или неправильные настройки, могут также повлиять на системы ИИ.
-   **Безопасность данных**: Защита обрабатываемых данных важна в обеих областях для предотвращения утечек данных и обеспечения их конфиденциальности.
-   **Безопасность цепочки поставок**: Оба типа систем подвержены атакам на цепочку поставок, когда скомпрометированный компонент может подорвать безопасность всей системы.

Эти сходства подчёркивают, что, несмотря на новые вызовы, которые создают системы ИИ, для их защиты также необходимо применять проверенные практики кибербезопасности. Это сочетание использования традиционного опыта в области безопасности и адаптации к уникальным аспектам технологии ИИ.

## Дополнительные материалы

- [Not with a Bug, But with a Sticker [Book] (oreilly.com)](https://www.oreilly.com/library/view/not-with-a/9781119883982/)
   
- [Intro to AI Security Part 1: AI Security 101 | by HarrietHacks | Medium](https://medium.com/@harrietfarlow/intro-to-ai-security-part-1-ai-security-101-b8662a9efe5)
   
- [Best practices for AI security risk management | Microsoft Security Blog](https://www.microsoft.com/en-us/security/blog/2021/12/09/best-practices-for-ai-security-risk-management/?WT.mc_id=academic-96948-sayoung)
   
- [OWASP AI Security and Privacy Guide | OWASP Foundation](https://owasp.org/www-project-ai-security-and-privacy-guide/)

---

**Отказ от ответственности**:  
Этот документ был переведен с помощью сервиса автоматического перевода [Co-op Translator](https://github.com/Azure/co-op-translator). Несмотря на наши усилия обеспечить точность, автоматические переводы могут содержать ошибки или неточности. Оригинальный документ на его родном языке следует считать авторитетным источником. Для получения критически важной информации рекомендуется профессиональный перевод человеком. Мы не несем ответственности за любые недоразумения или неправильные интерпретации, возникшие в результате использования данного перевода.