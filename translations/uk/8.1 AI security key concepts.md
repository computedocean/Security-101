<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "66b61d96936cf25d20fcb411d4ce5227",
  "translation_date": "2025-09-03T19:45:01+00:00",
  "source_file": "8.1 AI security key concepts.md",
  "language_code": "uk"
}
-->
# Основні концепції безпеки штучного інтелекту

[![Дивитися відео](../../translated_images/8-1_placeholder.00bf95633da13ca44348bde620f848337ccbd7ae4022459eab1df7f37421ba4e.uk.png)](https://learn-video.azurefd.net/vod/player?id=ba44f5f7-9b47-462f-9aa5-13e2b71f4998)

## Чим безпека штучного інтелекту відрізняється від традиційної кібербезпеки?

Забезпечення безпеки систем штучного інтелекту має унікальні виклики порівняно з традиційною кібербезпекою, головним чином через особливості навчальних можливостей і процесів прийняття рішень штучного інтелекту. Ось деякі ключові відмінності:

-   **Цілісність даних**: Системи штучного інтелекту значною мірою залежать від даних для навчання. [Забезпечення цілісності цих даних є критично важливим, оскільки зловмисники можуть маніпулювати даними, щоб вплинути на поведінку штучного інтелекту, що називається отруєнням даних.
-   **Безпека моделі**: Модель прийняття рішень штучного інтелекту сама може стати ціллю. [Зловмисники можуть спробувати зворотне проектування моделі або використати її слабкі місця для прийняття неправильних або шкідливих рішень.
-   **Атаки з використанням суперечливих даних**: Системи штучного інтелекту можуть бути вразливими до атак з використанням суперечливих даних, коли незначні, часто непомітні зміни вхідних даних можуть призвести до помилок або неправильних прогнозів.
-   **Безпека інфраструктури**: Хоча традиційна кібербезпека також зосереджена на захисті інфраструктури, системи штучного інтелекту можуть мати додаткові рівні складності, такі як хмарні сервіси або спеціалізоване обладнання, які потребують специфічних заходів безпеки.
-   **Етичні аспекти**: Використання штучного інтелекту в безпеці породжує етичні питання, такі як проблеми конфіденційності та потенційна упередженість у прийнятті рішень, які необхідно враховувати в стратегії безпеки.

Загалом, забезпечення безпеки систем штучного інтелекту вимагає іншого підходу, який враховує унікальні аспекти технології штучного інтелекту, включаючи захист даних, моделей і процесу навчання, а також вирішення етичних питань, пов'язаних із впровадженням штучного інтелекту.

Безпека штучного інтелекту та традиційна кібербезпека мають багато спільного, але також мають деякі суттєві відмінності через унікальні характеристики та можливості систем штучного інтелекту. Ось як вони відрізняються:

- **Складність загроз**: Системи штучного інтелекту додають нові рівні складності до кібербезпеки. Традиційна кібербезпека здебільшого має справу з загрозами, такими як шкідливе програмне забезпечення, фішингові атаки та вторгнення в мережу. Однак системи штучного інтелекту можуть бути вразливими до атак, таких як атаки з використанням суперечливих даних, отруєння даних і ухилення від моделі, які спеціально націлені на алгоритми машинного навчання.

- **Поверхня атаки**: Системи штучного інтелекту часто мають більшу поверхню атаки порівняно з традиційними системами. Це пов’язано з тим, що вони покладаються не лише на програмне забезпечення, але й на дані та моделі. Зловмисники можуть націлюватися на навчальні дані, маніпулювати моделями або використовувати вразливості самих алгоритмів.

- **Адаптивність загроз**: Системи штучного інтелекту можуть адаптуватися та навчатися з навколишнього середовища, що робить їх більш вразливими до адаптивних і еволюційних загроз. Традиційні заходи кібербезпеки можуть бути недостатніми для захисту від атак, які постійно змінюються залежно від поведінки системи штучного інтелекту.

- **Інтерпретація та пояснюваність**: Зрозуміти, чому система штучного інтелекту прийняла певне рішення, часто складніше порівняно з традиційними програмними системами. Ця відсутність інтерпретації та пояснюваності може ускладнити ефективне виявлення та пом’якшення атак на системи штучного інтелекту.

- **Проблеми конфіденційності даних**: Системи штучного інтелекту часто покладаються на великі обсяги даних, що може створювати ризики для конфіденційності, якщо дані не обробляються належним чином. Традиційні заходи кібербезпеки можуть бути недостатніми для вирішення цих проблем конфіденційності даних, специфічних для систем штучного інтелекту.

- **Регуляторна відповідність**: Регуляторне середовище для безпеки штучного інтелекту все ще розвивається, з’являються конкретні нормативи та стандарти для вирішення унікальних викликів, які створюють системи штучного інтелекту. Традиційні рамки кібербезпеки можуть потребувати розширення або адаптації для забезпечення відповідності цим новим нормативам.

- **Етичні аспекти**: Безпека штучного інтелекту передбачає не лише захист систем від зловмисних атак, але й забезпечення того, щоб системи штучного інтелекту використовувалися етично та відповідально. Це включає такі аспекти, як справедливість, прозорість і підзвітність, які можуть бути менш вираженими в традиційній кібербезпеці.

## Чим безпека штучного інтелекту схожа на захист традиційних ІТ-систем?

Забезпечення безпеки систем штучного інтелекту має кілька основних принципів, спільних із традиційною кібербезпекою:

-   **Захист від загроз**: Як системи штучного інтелекту, так і традиційні системи потребують захисту від несанкціонованого доступу, модифікації даних, їх знищення, а також інших поширених загроз.
-   **Управління вразливостями**: Багато вразливостей, які впливають на традиційні системи, такі як помилки програмного забезпечення або неправильні конфігурації, також можуть впливати на системи штучного інтелекту.
-   **Безпека даних**: Захист оброблюваних даних є важливим в обох сферах для запобігання витоку даних і забезпечення конфіденційності.
-   **Безпека ланцюга постачання**: Обидва типи систем вразливі до атак на ланцюг постачання, коли скомпрометований компонент може підірвати безпеку всієї системи.

Ці схожості підкреслюють, що хоча системи штучного інтелекту створюють нові виклики для безпеки, вони також потребують застосування усталених практик кібербезпеки для забезпечення надійного захисту. Це поєднання використання традиційної мудрості в галузі безпеки та адаптації до унікальних аспектів технології штучного інтелекту.

## Додаткова література

- [Not with a Bug, But with a Sticker [Book] (oreilly.com)](https://www.oreilly.com/library/view/not-with-a/9781119883982/)
   
- [Intro to AI Security Part 1: AI Security 101 | by HarrietHacks | Medium](https://medium.com/@harrietfarlow/intro-to-ai-security-part-1-ai-security-101-b8662a9efe5)
   
- [Best practices for AI security risk management | Microsoft Security Blog](https://www.microsoft.com/en-us/security/blog/2021/12/09/best-practices-for-ai-security-risk-management/?WT.mc_id=academic-96948-sayoung)
   
- [OWASP AI Security and Privacy Guide | OWASP Foundation](https://owasp.org/www-project-ai-security-and-privacy-guide/)

---

**Відмова від відповідальності**:  
Цей документ був перекладений за допомогою сервісу автоматичного перекладу [Co-op Translator](https://github.com/Azure/co-op-translator). Хоча ми прагнемо до точності, будь ласка, майте на увазі, що автоматичні переклади можуть містити помилки або неточності. Оригінальний документ на його рідній мові слід вважати авторитетним джерелом. Для критичної інформації рекомендується професійний людський переклад. Ми не несемо відповідальності за будь-які непорозуміння або неправильні тлумачення, що виникають внаслідок використання цього перекладу.