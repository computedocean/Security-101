<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "66b61d96936cf25d20fcb411d4ce5227",
  "translation_date": "2025-09-03T19:41:37+00:00",
  "source_file": "8.1 AI security key concepts.md",
  "language_code": "da"
}
-->
# AI-sikkerhed: centrale begreber

[![Se videoen](../../translated_images/8-1_placeholder.00bf95633da13ca44348bde620f848337ccbd7ae4022459eab1df7f37421ba4e.da.png)](https://learn-video.azurefd.net/vod/player?id=ba44f5f7-9b47-462f-9aa5-13e2b71f4998)

## Hvordan adskiller AI-sikkerhed sig fra traditionel cybersikkerhed?

Sikring af AI-systemer indebærer unikke udfordringer sammenlignet med traditionel cybersikkerhed, primært på grund af AI's læringsevner og beslutningsprocesser. Her er nogle væsentlige forskelle:

-   **Dataintegritet**: AI-systemer er stærkt afhængige af data til læring. [At sikre integriteten af disse data er afgørende, da angribere kan manipulere dataene for at påvirke AI's adfærd, en taktik kendt som dataforgiftning.
-   **Modelsikkerhed**: AI's beslutningsmodel kan være et mål. [Angribere kan forsøge at reverse-engineere modellen eller udnytte dens svagheder til at fremkalde forkerte eller skadelige beslutninger.
-   **Adversarielle angreb**: AI-systemer kan være sårbare over for adversarielle angreb, hvor små, ofte umærkelige ændringer i inputdata kan få AI til at begå fejl eller lave forkerte forudsigelser.
-   **Infrastruktursikkerhed**: Selvom traditionel cybersikkerhed også fokuserer på at beskytte infrastruktur, kan AI-systemer have ekstra lag af kompleksitet, såsom cloud-baserede tjenester eller specialiseret hardware, der kræver specifikke sikkerhedsforanstaltninger.
-   **Etiske overvejelser**: Brug af AI i sikkerhed medfører etiske overvejelser, såsom privatlivsproblemer og risikoen for bias i beslutningsprocesser, som skal adresseres i sikkerhedsstrategien.

Samlet set kræver sikring af AI-systemer en anderledes tilgang, der tager højde for de unikke aspekter af AI-teknologi, herunder beskyttelse af data, modeller og AI's læringsproces, samtidig med at de etiske implikationer af AI-implementering håndteres.

AI-sikkerhed og traditionel cybersikkerhed har mange ligheder, men de adskiller sig også på grund af de unikke karakteristika og kapaciteter ved kunstige intelligenssystemer. Her er hvordan de adskiller sig:

- **Kompleksitet af trusler**: AI-systemer introducerer nye lag af kompleksitet til cybersikkerhed. Traditionel cybersikkerhed håndterer primært trusler som malware, phishing-angreb og netværksindtrængninger. AI-systemer kan dog være sårbare over for angreb som adversarielle angreb, dataforgiftning og modelundvigelse, der specifikt retter sig mod maskinlæringsalgoritmerne.

- **Angrebsflade**: AI-systemer har ofte større angrebsflader sammenlignet med traditionelle systemer. Dette skyldes, at de ikke kun er afhængige af software, men også af data og modeller. Angribere kan målrette træningsdata, manipulere modeller eller udnytte sårbarheder i selve algoritmerne.

- **Truslers tilpasningsevne**: AI-systemer kan tilpasse sig og lære fra deres miljø, hvilket kan gøre dem mere modtagelige for adaptive og udviklende trusler. Traditionelle cybersikkerhedsforanstaltninger er muligvis ikke tilstrækkelige til at forsvare mod angreb, der konstant udvikler sig baseret på AI-systemets adfærd.

- **Fortolkning og forklarbarhed**: Det er ofte mere udfordrende at forstå, hvorfor et AI-system traf en bestemt beslutning sammenlignet med traditionelle softwaresystemer. Denne mangel på fortolkning og forklarbarhed kan gøre det vanskeligt effektivt at opdage og afbøde angreb på AI-systemer.

- **Databeskyttelse**: AI-systemer er ofte afhængige af store mængder data, hvilket kan medføre privatlivsrisici, hvis de ikke håndteres korrekt. Traditionelle cybersikkerhedsforanstaltninger adresserer muligvis ikke tilstrækkeligt disse databeskyttelsesproblemer, der er specifikke for AI-systemer.

- **Regulatorisk overholdelse**: Det regulatoriske landskab for AI-sikkerhed er stadig under udvikling, med specifikke regler og standarder, der opstår for at tackle de unikke udfordringer, som AI-systemer medfører. Traditionelle cybersikkerhedsrammer kan være nødt til at blive udvidet eller tilpasset for at sikre overholdelse af disse nye regler.

- **Etiske overvejelser**: AI-sikkerhed handler ikke kun om at beskytte systemer mod ondsindede angreb, men også om at sikre, at AI-systemer bruges på en etisk og ansvarlig måde. Dette inkluderer overvejelser som retfærdighed, gennemsigtighed og ansvarlighed, som måske ikke er lige så fremtrædende i traditionel cybersikkerhed.

## Hvordan er AI det samme som sikring af traditionelle IT-systemer?

Sikring af AI-systemer deler flere grundlæggende principper med traditionel cybersikkerhed:

-   **Trusselsbeskyttelse**: Både AI- og traditionelle systemer skal beskyttes mod uautoriseret adgang, datamodifikation og ødelæggelse samt andre almindelige trusler.
-   **Sårbarhedshåndtering**: Mange sårbarheder, der påvirker traditionelle systemer, såsom softwarefejl eller fejlkonfigurationer, kan også påvirke AI-systemer.
-   **Datasikkerhed**: Beskyttelse af behandlede data er afgørende i begge domæner for at forhindre databrud og sikre fortrolighed.
-   **Forsyningskædesikkerhed**: Begge typer systemer er modtagelige for angreb på forsyningskæden, hvor en kompromitteret komponent kan underminere sikkerheden i hele systemet.

Disse ligheder understreger, at selvom AI-systemer introducerer nye sikkerhedsudfordringer, kræver de også anvendelse af etablerede cybersikkerhedspraksisser for at sikre robust beskyttelse. Det er en blanding af at udnytte traditionel sikkerhedsviden og tilpasse sig de unikke aspekter af AI-teknologi.

## Yderligere læsning

- [Not with a Bug, But with a Sticker [Book] (oreilly.com)](https://www.oreilly.com/library/view/not-with-a/9781119883982/)
   
- [Intro to AI Security Part 1: AI Security 101 | by HarrietHacks | Medium](https://medium.com/@harrietfarlow/intro-to-ai-security-part-1-ai-security-101-b8662a9efe5)
   
- [Best practices for AI security risk management | Microsoft Security Blog](https://www.microsoft.com/en-us/security/blog/2021/12/09/best-practices-for-ai-security-risk-management/?WT.mc_id=academic-96948-sayoung)
   
- [OWASP AI Security and Privacy Guide | OWASP Foundation](https://owasp.org/www-project-ai-security-and-privacy-guide/)

---

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hjælp af AI-oversættelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestræber os på at sikre nøjagtighed, skal det bemærkes, at automatiserede oversættelser kan indeholde fejl eller unøjagtigheder. Det originale dokument på dets oprindelige sprog bør betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig oversættelse. Vi påtager os ikke ansvar for eventuelle misforståelser eller fejltolkninger, der måtte opstå som følge af brugen af denne oversættelse.