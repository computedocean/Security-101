<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "5e9775ee91bde7d44577891d5f11c4c5",
  "translation_date": "2025-09-03T18:28:49+00:00",
  "source_file": "8.3 Responsible AI.md",
  "language_code": "fa"
}
-->
# هوش مصنوعی مسئولانه

[![تماشای ویدیو](../../translated_images/8-3_placeholder.9a5623e020ef9751bfd82c06e3014edc976e2b2dc6ac5836571e63873a3c28b4.fa.png)](https://learn-video.azurefd.net/vod/player?id=b7517901-8f81-4475-b586-385a361c51e8)

## هوش مصنوعی مسئولانه چیست و چگونه به امنیت هوش مصنوعی مرتبط است؟

هوش مصنوعی مسئولانه به توسعه و استفاده از هوش مصنوعی به شیوه‌ای اخلاقی، شفاف و هماهنگ با ارزش‌های اجتماعی اشاره دارد. این مفهوم شامل اصولی مانند عدالت، پاسخگویی و استحکام است که تضمین می‌کند سیستم‌های هوش مصنوعی به گونه‌ای طراحی و اجرا شوند که به نفع افراد، جوامع و جامعه به طور کلی باشند.

ارتباط بین هوش مصنوعی مسئولانه و امنیت هوش مصنوعی اهمیت زیادی دارد زیرا:

-   **ملاحظات اخلاقی**: هوش مصنوعی مسئولانه شامل ملاحظات اخلاقی است که مستقیماً بر امنیت تأثیر می‌گذارد، مانند حفظ حریم خصوصی و حفاظت از داده‌ها. اطمینان از اینکه سیستم‌های هوش مصنوعی به حریم خصوصی کاربران احترام می‌گذارند و داده‌های شخصی را ایمن نگه می‌دارند، بخش مهمی از هوش مصنوعی مسئولانه است.
-   **استحکام و قابلیت اطمینان**: سیستم‌های هوش مصنوعی باید در برابر دستکاری و حملات مقاوم باشند، که این اصل اساسی هم در هوش مصنوعی مسئولانه و هم در امنیت هوش مصنوعی است. این شامل محافظت در برابر حملات خصمانه و تضمین یکپارچگی فرآیندهای تصمیم‌گیری هوش مصنوعی می‌شود.
-   **شفافیت و قابلیت توضیح**: بخشی از هوش مصنوعی مسئولانه این است که مطمئن شویم سیستم‌های هوش مصنوعی شفاف هستند و تصمیمات آن‌ها قابل توضیح است. این برای امنیت حیاتی است، زیرا ذینفعان باید درک کنند که سیستم‌های هوش مصنوعی چگونه کار می‌کنند تا به اقدامات امنیتی آن‌ها اعتماد کنند.
-   **پاسخگویی**: سیستم‌های هوش مصنوعی باید برای اقدامات خود پاسخگو باشند، به این معنا که باید مکانیزم‌هایی برای ردیابی تصمیمات و اصلاح مشکلات وجود داشته باشد. این با شیوه‌های امنیتی که فعالیت‌های سیستم را نظارت و ممیزی می‌کنند تا از نقض‌ها جلوگیری کرده و به آن‌ها پاسخ دهند، همسو است.

به طور کلی، هوش مصنوعی مسئولانه و امنیت هوش مصنوعی به هم مرتبط هستند، به طوری که شیوه‌های هوش مصنوعی مسئولانه امنیت سیستم‌های هوش مصنوعی را تقویت می‌کنند و بالعکس. اجرای اصول هوش مصنوعی مسئولانه به ایجاد سیستم‌های هوش مصنوعی کمک می‌کند که نه تنها از نظر اخلاقی درست هستند بلکه در برابر تهدیدات احتمالی نیز ایمن‌تر هستند.

## چگونه می‌توانم اطمینان حاصل کنم که سیستم هوش مصنوعی من هم ایمن است و هم اخلاقی؟

اطمینان از اینکه سیستم هوش مصنوعی شما هم ایمن است و هم اخلاقی، نیازمند یک رویکرد چندجانبه است که شامل مراحل زیر می‌شود:

- **پایبندی به اصول اخلاقی**: از دستورالعمل‌های اخلاقی تثبیت‌شده پیروی کنید که بر رفاه انسانی، اجتماعی و محیطی؛ عدالت؛ حفاظت از حریم خصوصی؛ قابلیت اطمینان؛ شفافیت؛ قابلیت اعتراض؛ و پاسخگویی تأکید دارند.

- **اجرای اقدامات امنیتی قوی**: از آزمایش‌های امنیتی پیشگیرانه و برنامه‌های مدیریت اعتماد، ریسک و امنیت هوش مصنوعی برای محافظت در برابر تهدیدات و آسیب‌پذیری‌ها استفاده کنید.

- **مشارکت ذینفعان متنوع**: طیف گسترده‌ای از شرکت‌کنندگان را در فرآیند توسعه هوش مصنوعی درگیر کنید، از جمله اخلاق‌دانان، دانشمندان اجتماعی و نمایندگان جوامع تحت تأثیر، تا اطمینان حاصل شود که دیدگاه‌ها و ارزش‌های متنوع در نظر گرفته می‌شوند.

- **اطمینان از شفافیت و قابلیت توضیح**: مطمئن شوید که فرآیندهای تصمیم‌گیری هوش مصنوعی شفاف هستند و قابل توضیح می‌باشند، که این امر اعتماد بیشتر و شناسایی آسان‌تر تعصبات یا خطاهای احتمالی را ممکن می‌سازد.

- **حفظ حریم خصوصی داده‌ها**: از طریق رمزنگاری و سایر اقدامات حفاظت از داده‌ها، حریم خصوصی و اصالت داده‌ها را حفظ کنید تا حقوق حریم خصوصی کاربران رعایت شود.

- **ایجاد نظارت انسانی**: مکانیزم‌هایی برای نظارت انسانی اجرا کنید تا امکان اعتراض به تصمیمات گرفته‌شده توسط سیستم‌های هوش مصنوعی و تضمین پاسخگویی فراهم شود.

- **آگاهی از ایمنی هوش مصنوعی**: با آخرین تحقیقات و بحث‌ها در مورد ایمنی هوش مصنوعی به‌روز باشید تا چشم‌انداز در حال تحول امنیت و اخلاق هوش مصنوعی را درک کنید.

- **رعایت قوانین و مقررات**: اطمینان حاصل کنید که سیستم هوش مصنوعی شما با تمام قوانین و مقررات مربوطه، از جمله قوانین حفاظت از داده‌ها، قوانین ضد تبعیض و دستورالعمل‌های خاص صنعت، مطابقت دارد.

## آیا می‌توانید چند نمونه از مشکلات امنیتی ناشی از استفاده غیراخلاقی از هوش مصنوعی ارائه دهید؟

در اینجا چند نمونه از مشکلات امنیتی که ممکن است از استفاده غیراخلاقی از هوش مصنوعی ناشی شوند آورده شده است:

- **تصمیم‌گیری متعصبانه**: سیستم‌های هوش مصنوعی ممکن است تعصبات موجود را تداوم بخشند و تقویت کنند اگر بر اساس مجموعه داده‌های متعصب آموزش داده شوند. به عنوان مثال، اگر یک موتور جستجو بر اساس داده‌هایی که منعکس‌کننده کلیشه‌های اجتماعی است آموزش داده شود، ممکن است نتایج جستجوی متعصبانه‌ای نمایش دهد که می‌تواند منجر به رفتار ناعادلانه یا تبعیض شود.

- **هوش مصنوعی در سیستم‌های قضایی**: استفاده از هوش مصنوعی در تصمیم‌گیری‌های قانونی می‌تواند نگرانی‌های اخلاقی ایجاد کند، به ویژه اگر فرآیند تصمیم‌گیری هوش مصنوعی فاقد شفافیت باشد یا تحت تأثیر داده‌های متعصب قرار گیرد. این امر می‌تواند منجر به نتایج قانونی ناعادلانه شود و حقوق افراد را نقض کند.

- **دستکاری سیستم‌های هوش مصنوعی**: سیستم‌های هوش مصنوعی ممکن است در برابر حملات خصمانه آسیب‌پذیر باشند، جایی که تغییرات جزئی در داده‌های ورودی می‌تواند منجر به نتایج نادرست شود. به عنوان مثال، وسایل نقلیه خودران ممکن است به اشتباه علائم راهنمایی و رانندگی را تفسیر کنند، که می‌تواند خطرات ایمنی ایجاد کند.

- **نظارت مبتنی بر هوش مصنوعی**: استفاده از هوش مصنوعی برای اهداف نظارتی می‌تواند منجر به نقض حریم خصوصی شود، به ویژه اگر بدون رضایت مناسب یا به روش‌هایی که آزادی‌های فردی را نقض می‌کند استفاده شود. این موضوع می‌تواند به‌ویژه در رژیم‌های استبدادی که ممکن است از هوش مصنوعی برای نظارت و سرکوب مخالفان استفاده کنند، مشکل‌ساز باشد.

این مثال‌ها اهمیت ملاحظات اخلاقی در توسعه و استقرار سیستم‌های هوش مصنوعی را برای جلوگیری از مشکلات امنیتی و حفاظت از حقوق و حریم خصوصی افراد برجسته می‌کنند.

## مطالعه بیشتر

 - [Microsoft Responsible AI Standard v2 General Requirements](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE5cmFl?culture=en-us&country=us&WT.mc_id=academic-96948-sayoung)
 - [Responsible AI (mit.edu)](https://sloanreview.mit.edu/big-ideas/responsible-ai/)
 - [13 Principles for Using AI Responsibly (hbr.org)](https://hbr.org/2023/06/13-principles-for-using-ai-responsibly)

---

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما تلاش می‌کنیم دقت را حفظ کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل خطاها یا نادرستی‌ها باشند. سند اصلی به زبان اصلی آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، توصیه می‌شود از ترجمه حرفه‌ای انسانی استفاده کنید. ما مسئولیتی در قبال سوء تفاهم‌ها یا تفسیرهای نادرست ناشی از استفاده از این ترجمه نداریم.