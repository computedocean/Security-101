<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b6bb7175672298d1e2f73ba7e0006f95",
  "translation_date": "2025-09-03T18:45:25+00:00",
  "source_file": "8.2 AI security capabilities.md",
  "language_code": "fa"
}
-->
# قابلیت‌های امنیتی هوش مصنوعی

[![تماشای ویدیو](../../translated_images/8-2_placeholder.bc988ce5dff1726a8b6f8c00b1250865ca23d02aa5cb11fb879ed1194702c99a.fa.png)](https://learn-video.azurefd.net/vod/player?id=e0a6f844-d884-4f76-99bd-4ce9f7f73d22)

## چه ابزارها و قابلیت‌هایی برای تأمین امنیت سیستم‌های هوش مصنوعی در حال حاضر وجود دارد؟

در حال حاضر، چندین ابزار و قابلیت برای تأمین امنیت سیستم‌های هوش مصنوعی در دسترس است:

-   **Counterfit**: یک ابزار متن‌باز برای خودکارسازی تست امنیتی سیستم‌های هوش مصنوعی که به سازمان‌ها کمک می‌کند ارزیابی ریسک امنیتی هوش مصنوعی را انجام دهند و از استحکام الگوریتم‌های خود اطمینان حاصل کنند.
-   **ابزارهای یادگیری ماشین مقابله‌ای**: این ابزارها استحکام مدل‌های یادگیری ماشین را در برابر حملات مقابله‌ای ارزیابی می‌کنند و به شناسایی و کاهش آسیب‌پذیری‌ها کمک می‌کنند.
-   **ابزارک‌های امنیتی هوش مصنوعی**: ابزارک‌های متن‌بازی وجود دارند که منابعی برای تأمین امنیت سیستم‌های هوش مصنوعی ارائه می‌دهند، از جمله کتابخانه‌ها و چارچوب‌هایی برای پیاده‌سازی اقدامات امنیتی.
-   **پلتفرم‌های همکاری**: همکاری بین شرکت‌ها و جوامع هوش مصنوعی برای توسعه اسکنرهای امنیتی خاص هوش مصنوعی و سایر ابزارها برای تأمین امنیت زنجیره تأمین هوش مصنوعی.

این ابزارها و قابلیت‌ها بخشی از یک حوزه در حال رشد هستند که به بهبود امنیت سیستم‌های هوش مصنوعی در برابر انواع تهدیدها اختصاص دارد. این تلاش‌ها ترکیبی از تحقیقات، ابزارهای عملی و همکاری‌های صنعتی است که به چالش‌های منحصربه‌فرد فناوری‌های هوش مصنوعی می‌پردازد.

## تیم قرمز هوش مصنوعی چیست؟ چه تفاوتی با تیم قرمز امنیت سنتی دارد؟

تیم قرمز هوش مصنوعی در چندین جنبه کلیدی با تیم قرمز امنیت سنتی تفاوت دارد:

-   **تمرکز بر سیستم‌های هوش مصنوعی**: تیم قرمز هوش مصنوعی به طور خاص آسیب‌پذیری‌های منحصربه‌فرد سیستم‌های هوش مصنوعی، مانند مدل‌های یادگیری ماشین و خطوط داده را هدف قرار می‌دهد، نه زیرساخت‌های سنتی فناوری اطلاعات.
-   **تست رفتار هوش مصنوعی**: این فرآیند شامل آزمایش نحوه واکنش سیستم‌های هوش مصنوعی به ورودی‌های غیرمعمول یا غیرمنتظره است که می‌تواند آسیب‌پذیری‌هایی را که ممکن است توسط مهاجمان بهره‌برداری شود، آشکار کند.
-   **بررسی شکست‌های هوش مصنوعی**: تیم قرمز هوش مصنوعی به شکست‌های مخرب و غیرمخرب می‌پردازد و مجموعه گسترده‌تری از شخصیت‌ها و شکست‌های احتمالی سیستم را فراتر از نقض‌های امنیتی در نظر می‌گیرد.
-   **تزریق دستورات و تولید محتوا**: این فرآیند شامل بررسی شکست‌هایی مانند تزریق دستورات است که در آن مهاجمان سیستم‌های هوش مصنوعی را برای تولید محتوای مضر یا بی‌اساس دستکاری می‌کنند.
-   **اخلاق و مسئولیت‌پذیری در هوش مصنوعی**: این بخش از اطمینان از طراحی مسئولانه هوش مصنوعی است که سیستم‌های هوش مصنوعی در برابر تلاش‌ها برای وادار کردن آن‌ها به رفتارهای ناخواسته مقاوم باشند.

به طور کلی، تیم قرمز هوش مصنوعی یک رویکرد گسترده‌تر است که نه تنها شامل بررسی آسیب‌پذیری‌های امنیتی می‌شود، بلکه تست انواع دیگر شکست‌های سیستم که مختص فناوری‌های هوش مصنوعی هستند را نیز در بر می‌گیرد. این یک بخش حیاتی از توسعه سیستم‌های هوش مصنوعی ایمن‌تر است که با درک و کاهش ریسک‌های جدید مرتبط با استقرار هوش مصنوعی همراه است.

## مطالعه بیشتر

 - [تیم قرمز هوش مصنوعی مایکروسافت آینده‌ای امن‌تر برای هوش مصنوعی می‌سازد | وبلاگ امنیت مایکروسافت](https://www.microsoft.com/en-us/security/blog/2023/08/07/microsoft-ai-red-team-building-future-of-safer-ai/?WT.mc_id=academic-96948-sayoung)
 - [اعلام چارچوب خودکار متن‌باز مایکروسافت برای تیم قرمز سیستم‌های هوش مصنوعی مولد | وبلاگ امنیت مایکروسافت](https://www.microsoft.com/en-us/security/blog/2024/02/22/announcing-microsofts-open-automation-framework-to-red-team-generative-ai-systems/?WT.mc_id=academic-96948-sayoung)
 - [ابزارهای امنیتی هوش مصنوعی: ابزارک متن‌باز | Wiz](https://www.wiz.io/academy/ai-security-tools)

---

**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما برای دقت تلاش می‌کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل خطاها یا نادرستی‌هایی باشند. سند اصلی به زبان بومی آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، ترجمه حرفه‌ای انسانی توصیه می‌شود. ما هیچ مسئولیتی در قبال سوءتفاهم‌ها یا تفسیرهای نادرست ناشی از استفاده از این ترجمه نداریم.