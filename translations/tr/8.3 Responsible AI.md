<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "5e9775ee91bde7d44577891d5f11c4c5",
  "translation_date": "2025-09-04T00:04:51+00:00",
  "source_file": "8.3 Responsible AI.md",
  "language_code": "tr"
}
-->
# Sorumlu Yapay Zeka

[![Videoyu İzle](../../translated_images/8-3_placeholder.9a5623e020ef9751bfd82c06e3014edc976e2b2dc6ac5836571e63873a3c28b4.tr.png)](https://learn-video.azurefd.net/vod/player?id=b7517901-8f81-4475-b586-385a361c51e8)

## Sorumlu yapay zeka nedir ve yapay zeka güvenliği ile nasıl ilişkilidir?

Sorumlu yapay zeka, yapay zekanın etik, şeffaf ve toplumsal değerlerle uyumlu bir şekilde geliştirilmesi ve kullanılması anlamına gelir. Adalet, hesap verebilirlik ve sağlamlık gibi ilkeleri kapsar ve yapay zeka sistemlerinin bireyler, topluluklar ve toplum için faydalı olacak şekilde tasarlanmasını ve işletilmesini sağlar.

Sorumlu yapay zeka ile yapay zeka güvenliği arasındaki ilişki önemlidir çünkü:

- **Etik Hususlar**: Sorumlu yapay zeka, güvenliği doğrudan etkileyen etik hususları içerir, örneğin gizlilik ve veri koruma. Yapay zeka sistemlerinin kullanıcı gizliliğine saygı göstermesi ve kişisel verileri güvence altına alması, sorumlu yapay zekanın önemli bir yönüdür.
- **Sağlamlık ve Güvenilirlik**: Yapay zeka sistemleri manipülasyon ve saldırılara karşı sağlam olmalıdır; bu, hem sorumlu yapay zekanın hem de yapay zeka güvenliğinin temel bir ilkesidir. Bu, düşmanca saldırılara karşı koruma sağlamayı ve yapay zeka karar verme süreçlerinin bütünlüğünü güvence altına almayı içerir.
- **Şeffaflık ve Açıklanabilirlik**: Sorumlu yapay zekanın bir parçası, yapay zeka sistemlerinin şeffaf olmasını ve kararlarının açıklanabilir olmasını sağlamaktır. Bu, güvenlik açısından önemlidir çünkü paydaşların yapay zeka sistemlerinin nasıl çalıştığını anlaması, güvenlik önlemlerine olan güveni artırır.
- **Hesap Verebilirlik**: Yapay zeka sistemleri, eylemlerinden sorumlu olmalıdır; bu da kararları izlemek ve sorunları düzeltmek için mekanizmalar bulunması gerektiği anlamına gelir. Bu, sistem faaliyetlerini izleyen ve denetleyen, ihlalleri önleyen ve bunlara yanıt veren güvenlik uygulamalarıyla uyumludur.

Özetle, sorumlu yapay zeka ve yapay zeka güvenliği birbirine bağlıdır; sorumlu yapay zeka uygulamaları, yapay zeka sistemlerinin güvenliğini artırır ve tam tersi. Sorumlu yapay zeka ilkelerini uygulamak, hem etik açıdan doğru hem de potansiyel tehditlere karşı daha güvenli yapay zeka sistemleri oluşturulmasına yardımcı olur.

## Yapay zeka sistemimin hem güvenli hem de etik olmasını nasıl sağlayabilirim?

Yapay zeka sisteminizin hem güvenli hem de etik olmasını sağlamak, aşağıdaki adımları içeren çok yönlü bir yaklaşımı gerektirir:

- **Etik İlkelere Uyun**: İnsan, toplumsal ve çevresel refah; adalet; gizlilik koruması; güvenilirlik; şeffaflık; itiraz edilebilirlik ve hesap verebilirlik gibi yerleşik etik yönergeleri takip edin.

- **Sağlam Güvenlik Önlemleri Uygulayın**: Tehditlere ve güvenlik açıklarına karşı koruma sağlamak için proaktif güvenlik testleri ve yapay zeka güven, risk ve güvenlik yönetimi programları kullanın.

- **Çeşitli Paydaşları Dahil Edin**: Etik uzmanları, sosyal bilimciler ve etkilenen toplulukların temsilcileri gibi geniş bir katılımcı yelpazesini yapay zeka geliştirme sürecine dahil ederek farklı bakış açıları ve değerlerin dikkate alınmasını sağlayın.

- **Şeffaflık ve Açıklanabilirlik Sağlayın**: Yapay zekanın karar verme süreçlerinin şeffaf ve açıklanabilir olmasını sağlayarak daha fazla güven oluşturun ve olası önyargıları veya hataları daha kolay tespit edin.

- **Veri Gizliliğini Koruyun**: Kullanıcıların gizlilik haklarına saygı göstermek için şifreleme ve diğer veri koruma önlemleriyle verilerin gizliliğini ve doğruluğunu koruyun.

- **İnsan Denetimini Etkinleştirin**: Yapay zeka sistemlerinin verdiği kararların itiraz edilebilirliğini sağlamak ve hesap verebilirliği temin etmek için insan denetimi mekanizmaları uygulayın.

- **Yapay Zeka Güvenliği Konusunda Bilgili Kalın**: Yapay zeka güvenliği ve etiği konusundaki gelişen durumu anlamak için en son araştırmaları ve tartışmaları takip edin.

- **Yönetmeliklere Uyun**: Yapay zeka sisteminizin veri koruma yasaları, ayrımcılık karşıtı yasalar ve sektöre özgü yönergeler gibi ilgili tüm yasa ve yönetmeliklere uygun olduğundan emin olun.

## Etik olmayan yapay zeka kullanımı nedeniyle oluşan bir güvenlik sorununa örnek verebilir misiniz?

İşte etik olmayan yapay zeka kullanımından kaynaklanabilecek güvenlik sorunlarına bazı örnekler:

- **Önyargılı Karar Verme**: Yapay zeka sistemleri, önyargılı veri setleriyle eğitildiklerinde mevcut önyargıları sürdürebilir ve artırabilir. Örneğin, bir arama motoru toplumsal klişeleri yansıtan verilerle eğitilirse, önyargılı arama sonuçları gösterebilir ve bu da adaletsiz muamele veya ayrımcılığa yol açabilir.

- **Yargı Sistemlerinde Yapay Zeka**: Yapay zekanın yasal karar verme süreçlerinde kullanılması, özellikle yapay zekanın karar verme süreci şeffaf değilse veya önyargılı verilerden etkileniyorsa, etik kaygılar doğurabilir. Bu, adaletsiz yasal sonuçlara ve bireylerin haklarının ihlaline neden olabilir.

- **Yapay Zeka Sistemlerinin Manipülasyonu**: Yapay zeka sistemleri, girdi verilerinde yapılan küçük değişikliklerle yanlış sonuçlara yol açan düşmanca saldırılara karşı savunmasız olabilir. Örneğin, otonom araçlar trafik işaretlerini yanlış yorumlamaya yönlendirilerek güvenlik riskleri oluşturabilir.

- **Yapay Zeka Destekli Gözetim**: Yapay zekanın gözetim amaçlı kullanımı, uygun izin olmadan veya bireysel özgürlükleri ihlal edecek şekilde kullanıldığında gizlilik ihlallerine yol açabilir. Bu, özellikle otoriter rejimlerde, yapay zekanın muhalefeti izlemek ve bastırmak için kullanılabileceği durumlarda sorunlu olabilir.

Bu örnekler, yapay zeka sistemlerinin geliştirilmesi ve uygulanmasında etik hususların güvenlik sorunlarını önlemek ve bireylerin haklarını ve gizliliğini korumak için önemini vurgulamaktadır.

## Daha fazla okuma

 - [Microsoft Responsible AI Standard v2 General Requirements](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE5cmFl?culture=en-us&country=us&WT.mc_id=academic-96948-sayoung)
 - [Responsible AI (mit.edu)](https://sloanreview.mit.edu/big-ideas/responsible-ai/)
 - [13 Principles for Using AI Responsibly (hbr.org)](https://hbr.org/2023/06/13-principles-for-using-ai-responsibly)

---

**Feragatname**:  
Bu belge, [Co-op Translator](https://github.com/Azure/co-op-translator) adlı yapay zeka çeviri hizmeti kullanılarak çevrilmiştir. Doğruluk için çaba göstersek de, otomatik çevirilerin hata veya yanlışlıklar içerebileceğini lütfen unutmayın. Orijinal belgenin kendi dilindeki hali yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler için profesyonel insan çevirisi önerilir. Bu çevirinin kullanımından kaynaklanan yanlış anlamalar veya yanlış yorumlamalardan sorumlu değiliz.