<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "66b61d96936cf25d20fcb411d4ce5227",
  "translation_date": "2025-09-03T19:44:13+00:00",
  "source_file": "8.1 AI security key concepts.md",
  "language_code": "it"
}
-->
# Concetti chiave sulla sicurezza dell'AI

[![Guarda il video](../../translated_images/8-1_placeholder.00bf95633da13ca44348bde620f848337ccbd7ae4022459eab1df7f37421ba4e.it.png)](https://learn-video.azurefd.net/vod/player?id=ba44f5f7-9b47-462f-9aa5-13e2b71f4998)

## In che modo la sicurezza dell'AI differisce dalla sicurezza informatica tradizionale?

Proteggere i sistemi di AI presenta sfide uniche rispetto alla sicurezza informatica tradizionale, principalmente a causa della natura delle capacità di apprendimento e dei processi decisionali dell'AI. Ecco alcune differenze chiave:

-   **Integrità dei dati**: I sistemi di AI si basano fortemente sui dati per apprendere. Garantire l'integrità di questi dati è fondamentale, poiché gli attaccanti possono manipolarli per influenzare il comportamento dell'AI, una tattica nota come avvelenamento dei dati.
-   **Sicurezza del modello**: Il modello decisionale dell'AI stesso può essere un bersaglio. Gli attaccanti potrebbero tentare di reverse-engineer il modello o sfruttarne le vulnerabilità per indurre decisioni errate o dannose.
-   **Attacchi avversari**: I sistemi di AI possono essere vulnerabili agli attacchi avversari, in cui lievi, spesso impercettibili, alterazioni dei dati di input possono causare errori o previsioni errate da parte dell'AI.
-   **Sicurezza dell'infrastruttura**: Sebbene la sicurezza informatica tradizionale si concentri anche sulla protezione dell'infrastruttura, i sistemi di AI possono avere livelli di complessità aggiuntivi, come servizi basati su cloud o hardware specializzato, che richiedono misure di sicurezza specifiche.
-   **Considerazioni etiche**: L'uso dell'AI nella sicurezza solleva considerazioni etiche, come preoccupazioni sulla privacy e il potenziale di bias nei processi decisionali, che devono essere affrontate nella strategia di sicurezza.

In generale, proteggere i sistemi di AI richiede un approccio diverso che consideri gli aspetti unici della tecnologia AI, inclusa la protezione dei dati, dei modelli e del processo di apprendimento dell'AI, affrontando al contempo le implicazioni etiche della sua implementazione.

La sicurezza dell'AI e la sicurezza informatica tradizionale condividono molte somiglianze, ma presentano anche alcune differenze distintive a causa delle caratteristiche e capacità uniche dei sistemi di intelligenza artificiale. Ecco come si differenziano:

- **Complessità delle minacce**: I sistemi di AI introducono nuovi livelli di complessità nella sicurezza informatica. La sicurezza informatica tradizionale si occupa principalmente di minacce come malware, attacchi di phishing e intrusioni di rete. Tuttavia, i sistemi di AI possono essere vulnerabili ad attacchi come attacchi avversari, avvelenamento dei dati e evasione del modello, che prendono di mira specificamente gli algoritmi di apprendimento automatico.

- **Superficie di attacco**: I sistemi di AI spesso hanno superfici di attacco più ampie rispetto ai sistemi tradizionali. Questo perché si basano non solo sul software, ma anche sui dati e sui modelli. Gli attaccanti possono prendere di mira i dati di addestramento, manipolare i modelli o sfruttare le vulnerabilità degli algoritmi stessi.

- **Adattabilità delle minacce**: I sistemi di AI possono adattarsi e apprendere dal loro ambiente, il che li rende più suscettibili a minacce adattive ed evolutive. Le misure di sicurezza informatica tradizionali potrebbero non essere sufficienti per difendersi da attacchi che si evolvono costantemente in base al comportamento del sistema di AI.

- **Interpretabilità e spiegabilità**: Comprendere perché un sistema di AI ha preso una determinata decisione è spesso più difficile rispetto ai sistemi software tradizionali. Questa mancanza di interpretabilità e spiegabilità può rendere difficile rilevare e mitigare efficacemente gli attacchi ai sistemi di AI.

- **Preoccupazioni sulla privacy dei dati**: I sistemi di AI si basano spesso su grandi quantità di dati, il che può introdurre rischi per la privacy se non gestiti correttamente. Le misure di sicurezza informatica tradizionali potrebbero non affrontare adeguatamente queste preoccupazioni specifiche per i sistemi di AI.

- **Conformità normativa**: Il panorama normativo per la sicurezza dell'AI è ancora in evoluzione, con regolamenti e standard specifici che emergono per affrontare le sfide uniche poste dai sistemi di AI. I framework di sicurezza informatica tradizionali potrebbero dover essere estesi o adattati per garantire la conformità a queste nuove normative.

- **Considerazioni etiche**: La sicurezza dell'AI non riguarda solo la protezione dei sistemi da attacchi malevoli, ma anche garantire che i sistemi di AI siano utilizzati in modo etico e responsabile. Questo include considerazioni come equità, trasparenza e responsabilità, che potrebbero non essere così prominenti nella sicurezza informatica tradizionale.

## In che modo la sicurezza dell'AI è simile alla protezione dei sistemi IT tradizionali?

Proteggere i sistemi di AI condivide diversi principi fondamentali con la sicurezza informatica tradizionale:

-   **Protezione dalle minacce**: Sia i sistemi di AI che quelli tradizionali devono essere protetti contro accessi non autorizzati, modifiche ai dati e distruzione, oltre ad altre minacce comuni.
-   **Gestione delle vulnerabilità**: Molte vulnerabilità che colpiscono i sistemi tradizionali, come bug software o configurazioni errate, possono influenzare anche i sistemi di AI.
-   **Sicurezza dei dati**: La protezione dei dati elaborati è cruciale in entrambi i domini per prevenire violazioni dei dati e garantire la riservatezza.
-   **Sicurezza della catena di approvvigionamento**: Entrambi i tipi di sistemi sono suscettibili agli attacchi alla catena di approvvigionamento, in cui un componente compromesso può minare la sicurezza dell'intero sistema.

Queste somiglianze evidenziano che, sebbene i sistemi di AI introducano nuove sfide di sicurezza, richiedono anche l'applicazione di pratiche consolidate di sicurezza informatica per garantire una protezione robusta. È una combinazione di saggezza tradizionale in materia di sicurezza e adattamento agli aspetti unici della tecnologia AI.

## Ulteriori letture

- [Not with a Bug, But with a Sticker [Book] (oreilly.com)](https://www.oreilly.com/library/view/not-with-a/9781119883982/)
   
- [Intro to AI Security Part 1: AI Security 101 | by HarrietHacks | Medium](https://medium.com/@harrietfarlow/intro-to-ai-security-part-1-ai-security-101-b8662a9efe5)
   
- [Best practices for AI security risk management | Microsoft Security Blog](https://www.microsoft.com/en-us/security/blog/2021/12/09/best-practices-for-ai-security-risk-management/?WT.mc_id=academic-96948-sayoung)
   
- [OWASP AI Security and Privacy Guide | OWASP Foundation](https://owasp.org/www-project-ai-security-and-privacy-guide/)

---

**Disclaimer**:  
Questo documento è stato tradotto utilizzando il servizio di traduzione automatica [Co-op Translator](https://github.com/Azure/co-op-translator). Sebbene ci impegniamo per garantire l'accuratezza, si prega di notare che le traduzioni automatiche possono contenere errori o imprecisioni. Il documento originale nella sua lingua nativa dovrebbe essere considerato la fonte autorevole. Per informazioni critiche, si raccomanda una traduzione professionale effettuata da un traduttore umano. Non siamo responsabili per eventuali incomprensioni o interpretazioni errate derivanti dall'uso di questa traduzione.