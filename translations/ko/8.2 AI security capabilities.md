<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b6bb7175672298d1e2f73ba7e0006f95",
  "translation_date": "2025-09-03T18:46:18+00:00",
  "source_file": "8.2 AI security capabilities.md",
  "language_code": "ko"
}
-->
# AI 보안 기능

[![Watch the video](../../translated_images/8-2_placeholder.bc988ce5dff1726a8b6f8c00b1250865ca23d02aa5cb11fb879ed1194702c99a.ko.png)](https://learn-video.azurefd.net/vod/player?id=e0a6f844-d884-4f76-99bd-4ce9f7f73d22)

## 현재 AI 시스템을 보호하기 위해 어떤 도구와 기능이 있나요?

현재 AI 시스템을 보호하기 위해 사용할 수 있는 여러 도구와 기능이 있습니다:

-   **Counterfit**: AI 시스템의 보안 테스트를 자동화하는 오픈 소스 도구로, 조직이 AI 보안 위험 평가를 수행하고 알고리즘의 견고성을 보장할 수 있도록 설계되었습니다.
-   **적대적 머신 러닝 도구**: 머신 러닝 모델이 적대적 공격에 얼마나 견고한지 평가하는 도구로, 취약점을 식별하고 완화하는 데 도움을 줍니다.
-   **AI 보안 툴킷**: AI 시스템 보안을 위한 리소스를 제공하는 오픈 소스 툴킷으로, 보안 조치를 구현하기 위한 라이브러리와 프레임워크를 포함합니다.
-   **협업 플랫폼**: 기업과 AI 커뮤니티 간의 협력을 통해 AI 공급망을 보호하기 위한 AI 전용 보안 스캐너 및 기타 도구를 개발합니다.

이러한 도구와 기능은 다양한 위협으로부터 AI 시스템의 보안을 강화하기 위한 성장하는 분야의 일부입니다. 이는 연구, 실용적인 도구, 산업 협력을 결합하여 AI 기술이 직면한 독특한 과제를 해결하는 데 초점을 맞추고 있습니다.

## AI 레드 팀 활동은 무엇인가요? 기존 보안 레드 팀 활동과 어떻게 다른가요?

AI 레드 팀 활동은 기존 보안 레드 팀 활동과 몇 가지 주요 측면에서 다릅니다:

-   **AI 시스템에 초점**: AI 레드 팀 활동은 전통적인 IT 인프라가 아닌 머신 러닝 모델과 데이터 파이프라인 같은 AI 시스템의 고유한 취약점을 대상으로 합니다.
-   **AI 행동 테스트**: AI 시스템이 비정상적이거나 예상치 못한 입력에 어떻게 반응하는지 테스트하여 공격자가 악용할 수 있는 취약점을 드러냅니다.
-   **AI 실패 탐구**: 악의적 실패뿐만 아니라 정상적인 실패도 고려하며, 단순한 보안 침해를 넘어 더 광범위한 페르소나와 시스템 실패 가능성을 탐구합니다.
-   **프롬프트 주입 및 콘텐츠 생성**: AI 레드 팀 활동은 공격자가 AI 시스템을 조작해 유해하거나 근거 없는 콘텐츠를 생성하도록 만드는 프롬프트 주입과 같은 실패를 탐색하는 것도 포함합니다.
-   **윤리적이고 책임 있는 AI**: 이는 설계 단계에서부터 책임 있는 AI를 보장하는 과정의 일부로, AI 시스템이 의도하지 않은 방식으로 작동하지 않도록 견고성을 확보하는 데 중점을 둡니다.

결론적으로, AI 레드 팀 활동은 보안 취약점을 탐색하는 것뿐만 아니라 AI 기술에 특화된 다른 유형의 시스템 실패를 테스트하는 확장된 실천 방식입니다. 이는 AI 배포와 관련된 새로운 위험을 이해하고 완화함으로써 더 안전한 AI 시스템을 개발하는 데 중요한 역할을 합니다.

## 추가 읽을거리

 - [Microsoft AI Red Team building future of safer AI | Microsoft Security Blog](https://www.microsoft.com/en-us/security/blog/2023/08/07/microsoft-ai-red-team-building-future-of-safer-ai/?WT.mc_id=academic-96948-sayoung)
 - [Announcing Microsoft’s open automation framework to red team generative AI Systems | Microsoft Security Blog](https://www.microsoft.com/en-us/security/blog/2024/02/22/announcing-microsofts-open-automation-framework-to-red-team-generative-ai-systems/?WT.mc_id=academic-96948-sayoung)
 - [AI Security Tools: The Open-Source Toolkit | Wiz](https://www.wiz.io/academy/ai-security-tools)

---

**면책 조항**:  
이 문서는 AI 번역 서비스 [Co-op Translator](https://github.com/Azure/co-op-translator)를 사용하여 번역되었습니다. 정확성을 위해 최선을 다하고 있으나, 자동 번역에는 오류나 부정확성이 포함될 수 있습니다. 원본 문서를 해당 언어로 작성된 상태에서 권위 있는 자료로 간주해야 합니다. 중요한 정보의 경우, 전문적인 인간 번역을 권장합니다. 이 번역 사용으로 인해 발생하는 오해나 잘못된 해석에 대해 당사는 책임을 지지 않습니다.  