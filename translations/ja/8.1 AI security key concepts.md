<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "66b61d96936cf25d20fcb411d4ce5227",
  "translation_date": "2025-09-03T19:44:31+00:00",
  "source_file": "8.1 AI security key concepts.md",
  "language_code": "ja"
}
-->
# AIセキュリティの重要な概念

[![動画を見る](../../translated_images/8-1_placeholder.00bf95633da13ca44348bde620f848337ccbd7ae4022459eab1df7f37421ba4e.ja.png)](https://learn-video.azurefd.net/vod/player?id=ba44f5f7-9b47-462f-9aa5-13e2b71f4998)

## AIセキュリティは従来のサイバーセキュリティとどう異なるのか？

AIシステムのセキュリティを確保することは、AIの学習能力や意思決定プロセスの性質により、従来のサイバーセキュリティとは異なる独自の課題を提示します。以下は主な違いです：

-   **データの整合性**: AIシステムは学習にデータを大きく依存しています。[このデータの整合性を確保することが重要であり、攻撃者がデータを操作してAIの挙動に影響を与える「データポイズニング」と呼ばれる手法を使用する可能性があります。
-   **モデルのセキュリティ**: AIの意思決定モデル自体が攻撃対象となる可能性があります。[攻撃者はモデルを逆解析したり、その弱点を突いて誤ったまたは有害な決定を下させることを試みる可能性があります。
-   **敵対的攻撃**: AIシステムは敵対的攻撃に対して脆弱である可能性があります。これは、入力データにわずかな、しばしば目に見えない変更を加えることで、AIが誤りや不正確な予測をするように仕向ける攻撃です。
-   **インフラのセキュリティ**: 従来のサイバーセキュリティもインフラの保護に焦点を当てていますが、AIシステムにはクラウドベースのサービスや特殊なハードウェアなど、特定のセキュリティ対策が必要な追加の複雑さがある場合があります。
-   **倫理的考慮**: セキュリティにおけるAIの使用は、プライバシーの懸念や意思決定における偏りの可能性など、倫理的な考慮を伴い、セキュリティ戦略でこれらに対処する必要があります。

全体として、AIシステムのセキュリティを確保するには、データ、モデル、AIの学習プロセスの保護を含むAI技術の独自の側面を考慮し、AI導入の倫理的影響にも対応する異なるアプローチが必要です。

---

AIセキュリティと従来のサイバーセキュリティには多くの共通点がありますが、人工知能システムの独自の特性と能力により、いくつかの明確な違いも存在します。以下はその違いです：

- **脅威の複雑さ**: AIシステムはサイバーセキュリティに新たな複雑さをもたらします。従来のサイバーセキュリティは主にマルウェア、フィッシング攻撃、ネットワーク侵入などの脅威に対処しますが、AIシステムは敵対的攻撃、データポイズニング、モデル回避など、機械学習アルゴリズム自体を標的とする攻撃に対して脆弱である可能性があります。

- **攻撃対象の範囲**: AIシステムは従来のシステムよりも攻撃対象の範囲が広いことがよくあります。これは、ソフトウェアだけでなくデータやモデルにも依存しているためです。攻撃者はトレーニングデータを標的にしたり、モデルを操作したり、アルゴリズム自体の脆弱性を悪用する可能性があります。

- **脅威の適応性**: AIシステムは環境から学び適応することができるため、適応的で進化する脅威に対してより脆弱になる可能性があります。従来のサイバーセキュリティ対策では、AIシステムの挙動に基づいて絶えず進化する攻撃に対抗するには不十分な場合があります。

- **解釈性と説明可能性**: AIシステムが特定の決定を下した理由を理解することは、従来のソフトウェアシステムと比較してしばしば困難です。この解釈性と説明可能性の欠如は、AIシステムへの攻撃を効果的に検出し、軽減することを難しくする可能性があります。

- **データプライバシーの懸念**: AIシステムは大量のデータに依存することが多く、適切に扱われない場合、プライバシーリスクを引き起こす可能性があります。従来のサイバーセキュリティ対策では、AIシステム特有のデータプライバシーの懸念に十分に対応できない場合があります。

- **規制遵守**: AIセキュリティに関する規制の状況はまだ進化しており、AIシステムがもたらす独自の課題に対処するための特定の規制や基準が登場しています。従来のサイバーセキュリティフレームワークは、これらの新しい規制に準拠するために拡張または適応する必要がある場合があります。

- **倫理的考慮**: AIセキュリティは、悪意ある攻撃からシステムを保護するだけでなく、AIシステムが倫理的かつ責任ある方法で使用されることを保証することも含みます。これには、公平性、透明性、説明責任などの考慮が含まれ、従来のサイバーセキュリティではそれほど顕著ではない場合があります。

---

## AIセキュリティは従来のITシステムのセキュリティとどう同じなのか？

AIシステムのセキュリティは、従来のサイバーセキュリティといくつかの基本的な原則を共有しています：

-   **脅威保護**: AIと従来のシステムの両方は、不正アクセス、データの改ざん、破壊、その他の一般的な脅威から保護される必要があります。
-   **脆弱性管理**: ソフトウェアのバグや設定ミスなど、従来のシステムに影響を与える多くの脆弱性は、AIシステムにも影響を与える可能性があります。
-   **データセキュリティ**: 処理されるデータの保護は、データ漏洩を防ぎ、機密性を確保するために両方の領域で重要です。
-   **サプライチェーンセキュリティ**: 両方のタイプのシステムは、コンポーネントが侵害されることでシステム全体のセキュリティが損なわれるサプライチェーン攻撃に対して脆弱です。

これらの類似点は、AIシステムが新しいセキュリティ課題をもたらす一方で、確固たる保護を確保するために確立されたサイバーセキュリティの実践を適用する必要があることを示しています。従来のセキュリティの知恵を活用しつつ、AI技術の独自の側面に適応することが求められます。

---

## 参考文献

- [Not with a Bug, But with a Sticker [Book] (oreilly.com)](https://www.oreilly.com/library/view/not-with-a/9781119883982/)
   
- [Intro to AI Security Part 1: AI Security 101 | by HarrietHacks | Medium](https://medium.com/@harrietfarlow/intro-to-ai-security-part-1-ai-security-101-b8662a9efe5)
   
- [Best practices for AI security risk management | Microsoft Security Blog](https://www.microsoft.com/en-us/security/blog/2021/12/09/best-practices-for-ai-security-risk-management/?WT.mc_id=academic-96948-sayoung)
   
- [OWASP AI Security and Privacy Guide | OWASP Foundation](https://owasp.org/www-project-ai-security-and-privacy-guide/)

---

**免責事項**:  
この文書はAI翻訳サービス[Co-op Translator](https://github.com/Azure/co-op-translator)を使用して翻訳されています。正確性を追求しておりますが、自動翻訳には誤りや不正確な部分が含まれる可能性があります。元の言語で記載された文書を正式な情報源としてご参照ください。重要な情報については、専門の人間による翻訳を推奨します。この翻訳の使用に起因する誤解や誤解釈について、当方は責任を負いません。