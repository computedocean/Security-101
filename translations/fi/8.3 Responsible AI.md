<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "5e9775ee91bde7d44577891d5f11c4c5",
  "translation_date": "2025-09-03T20:46:33+00:00",
  "source_file": "8.3 Responsible AI.md",
  "language_code": "fi"
}
-->
# Vastuullinen tekoäly

[![Katso video](../../translated_images/8-3_placeholder.9a5623e020ef9751bfd82c06e3014edc976e2b2dc6ac5836571e63873a3c28b4.fi.png)](https://learn-video.azurefd.net/vod/player?id=b7517901-8f81-4475-b586-385a361c51e8)

## Mitä vastuullinen tekoäly on ja miten se liittyy tekoälyn turvallisuuteen?

Vastuullinen tekoäly tarkoittaa tekoälyn kehittämistä ja käyttöä tavalla, joka on eettinen, läpinäkyvä ja yhteiskunnan arvojen mukainen. Se sisältää periaatteita, kuten oikeudenmukaisuus, vastuullisuus ja luotettavuus, ja varmistaa, että tekoälyjärjestelmät on suunniteltu ja toteutettu hyödyttämään yksilöitä, yhteisöjä ja yhteiskuntaa kokonaisuudessaan.

Vastuullisen tekoälyn ja tekoälyn turvallisuuden välinen suhde on merkittävä, koska:

-   **Eettiset näkökohdat**: Vastuullinen tekoäly huomioi eettiset näkökohdat, jotka vaikuttavat suoraan turvallisuuteen, kuten yksityisyyden suoja ja tietoturva. On tärkeää varmistaa, että tekoälyjärjestelmät kunnioittavat käyttäjien yksityisyyttä ja suojaavat henkilökohtaisia tietoja.
-   **Luotettavuus ja kestävyys**: Tekoälyjärjestelmien on oltava kestäviä manipulointia ja hyökkäyksiä vastaan, mikä on keskeinen periaate sekä vastuullisessa tekoälyssä että tekoälyn turvallisuudessa. Tämä sisältää suojautumisen vihamielisiltä hyökkäyksiltä ja tekoälyn päätöksentekoprosessien eheyden varmistamisen.
-   **Läpinäkyvyys ja selitettävyys**: Osa vastuullista tekoälyä on varmistaa, että tekoälyjärjestelmät ovat läpinäkyviä ja niiden päätöksiä voidaan selittää. Tämä on tärkeää turvallisuuden kannalta, sillä sidosryhmien on ymmärrettävä, miten tekoälyjärjestelmät toimivat, jotta ne voivat luottaa niiden turvallisuustoimenpiteisiin.
-   **Vastuullisuus**: Tekoälyjärjestelmien on oltava vastuussa toiminnastaan, mikä tarkoittaa, että päätöksiä on voitava jäljittää ja mahdolliset ongelmat korjata. Tämä on linjassa turvallisuuskäytäntöjen kanssa, jotka seuraavat ja auditoivat järjestelmien toimintaa estääkseen ja vastatakseen rikkomuksiin.

Yhteenvetona voidaan todeta, että vastuullinen tekoäly ja tekoälyn turvallisuus ovat tiiviisti yhteydessä toisiinsa. Vastuullisen tekoälyn periaatteiden noudattaminen parantaa tekoälyjärjestelmien turvallisuutta ja päinvastoin. Vastuullisen tekoälyn toteuttaminen auttaa luomaan tekoälyjärjestelmiä, jotka ovat sekä eettisesti kestäviä että turvallisia mahdollisia uhkia vastaan.

## Miten voin varmistaa, että tekoälyjärjestelmäni on sekä turvallinen että eettinen?

Tekoälyjärjestelmän turvallisuuden ja eettisyyden varmistaminen edellyttää monipuolista lähestymistapaa, joka sisältää seuraavat vaiheet:

- **Noudata eettisiä periaatteita**: Seuraa vakiintuneita eettisiä ohjeita, jotka korostavat ihmisten, yhteiskunnan ja ympäristön hyvinvointia; oikeudenmukaisuutta; yksityisyyden suojaa; luotettavuutta; läpinäkyvyyttä; kiistettävyyttä ja vastuullisuutta.

- **Toteuta vahvat turvallisuustoimenpiteet**: Käytä ennakoivaa turvallisuustestausta ja tekoälyn luottamuksen, riskien ja turvallisuuden hallintaohjelmia suojautuaksesi uhkilta ja haavoittuvuuksilta.

- **Osallista monipuolisia sidosryhmiä**: Ota mukaan laaja joukko osallistujia tekoälyn kehitysprosessiin, mukaan lukien eettisiä asiantuntijoita, yhteiskuntatieteilijöitä ja vaikutuksen kohteena olevien yhteisöjen edustajia, jotta erilaiset näkökulmat ja arvot tulevat huomioiduiksi.

- **Varmista läpinäkyvyys ja selitettävyys**: Huolehdi siitä, että tekoälyn päätöksentekoprosessit ovat läpinäkyviä ja selitettävissä, mikä lisää luottamusta ja helpottaa mahdollisten ennakkoluulojen tai virheiden tunnistamista.

- **Säilytä tietosuoja**: Suojaa tietojen yksityisyys ja aitous salauksen ja muiden tietosuojatoimenpiteiden avulla kunnioittaaksesi käyttäjien yksityisyyttä.

- **Mahdollista ihmisen valvonta**: Ota käyttöön mekanismeja, jotka mahdollistavat tekoälyn päätösten kiistämisen ja varmistavat vastuullisuuden.

- **Pysy ajan tasalla tekoälyn turvallisuudesta**: Seuraa uusinta tutkimusta ja keskustelua tekoälyn turvallisuudesta ymmärtääksesi tekoälyn turvallisuuden ja etiikan muuttuvaa kenttää.

- **Noudata säädöksiä**: Varmista, että tekoälyjärjestelmäsi noudattaa kaikkia asiaankuuluvia lakeja ja säädöksiä, kuten tietosuojalakeja, syrjinnän vastaisia lakeja ja toimialakohtaisia ohjeita.

## Voitko antaa esimerkkejä turvallisuusongelmista, jotka johtuvat tekoälyn epäeettisestä käytöstä?

Tässä on joitakin esimerkkejä turvallisuusongelmista, jotka voivat syntyä tekoälyn epäeettisestä käytöstä:

- **Vääristynyt päätöksenteko**: Tekoälyjärjestelmät voivat ylläpitää ja vahvistaa olemassa olevia ennakkoluuloja, jos ne on koulutettu puolueellisilla aineistoilla. Esimerkiksi, jos hakukone on koulutettu aineistolla, joka heijastaa yhteiskunnallisia stereotypioita, se voi näyttää puolueellisia hakutuloksia, mikä voi johtaa epäoikeudenmukaiseen kohteluun tai syrjintään.

- **Tekoäly oikeusjärjestelmissä**: Tekoälyn käyttö oikeudellisessa päätöksenteossa voi herättää eettisiä huolenaiheita, erityisesti jos tekoälyn päätöksentekoprosessi ei ole läpinäkyvä tai se perustuu puolueellisiin tietoihin. Tämä voi johtaa epäoikeudenmukaisiin oikeudellisiin lopputuloksiin ja loukata yksilöiden oikeuksia.

- **Tekoälyjärjestelmien manipulointi**: Tekoälyjärjestelmät voivat olla alttiita vihamielisille hyökkäyksille, joissa pienet muutokset syötedatassa voivat aiheuttaa virheellisiä tuloksia. Esimerkiksi autonomiset ajoneuvot voidaan harhauttaa tulkitsemaan liikennemerkkejä väärin, mikä voi aiheuttaa turvallisuusriskejä.

- **Tekoälyyn perustuva valvonta**: Tekoälyn käyttö valvontatarkoituksiin voi johtaa yksityisyyden loukkauksiin, erityisesti jos sitä käytetään ilman asianmukaista suostumusta tai tavoilla, jotka rajoittavat yksilön vapauksia. Tämä voi olla erityisen ongelmallista autoritaarisissa hallinnoissa, jotka saattavat käyttää tekoälyä kansalaisten valvontaan ja toisinajattelun tukahduttamiseen.

Nämä esimerkit korostavat eettisten näkökohtien merkitystä tekoälyjärjestelmien kehittämisessä ja käyttöönotossa turvallisuusongelmien ehkäisemiseksi ja yksilöiden oikeuksien ja yksityisyyden suojaamiseksi.

## Lisälukemista

 - [Microsoft Responsible AI Standard v2 General Requirements](https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RE5cmFl?culture=en-us&country=us&WT.mc_id=academic-96948-sayoung)
 - [Responsible AI (mit.edu)](https://sloanreview.mit.edu/big-ideas/responsible-ai/)
 - [13 Principles for Using AI Responsibly (hbr.org)](https://hbr.org/2023/06/13-principles-for-using-ai-responsibly)

---

**Vastuuvapauslauseke**:  
Tämä asiakirja on käännetty käyttämällä tekoälypohjaista käännöspalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Vaikka pyrimme tarkkuuteen, huomioithan, että automaattiset käännökset voivat sisältää virheitä tai epätarkkuuksia. Alkuperäistä asiakirjaa sen alkuperäisellä kielellä tulisi pitää ensisijaisena lähteenä. Kriittisen tiedon osalta suositellaan ammattimaista ihmiskäännöstä. Emme ole vastuussa väärinkäsityksistä tai virhetulkinnoista, jotka johtuvat tämän käännöksen käytöstä.