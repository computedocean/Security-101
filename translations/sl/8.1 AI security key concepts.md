<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "66b61d96936cf25d20fcb411d4ce5227",
  "translation_date": "2025-09-03T22:51:47+00:00",
  "source_file": "8.1 AI security key concepts.md",
  "language_code": "sl"
}
-->
# Ključni koncepti varnosti umetne inteligence

[![Oglejte si video](../../translated_images/8-1_placeholder.00bf95633da13ca44348bde620f848337ccbd7ae4022459eab1df7f37421ba4e.sl.png)](https://learn-video.azurefd.net/vod/player?id=ba44f5f7-9b47-462f-9aa5-13e2b71f4998)

## Kako se varnost umetne inteligence razlikuje od tradicionalne kibernetske varnosti?

Zagotavljanje varnosti sistemov umetne inteligence prinaša edinstvene izzive v primerjavi s tradicionalno kibernetsko varnostjo, predvsem zaradi narave učenja in procesov odločanja umetne inteligence. Tukaj so ključne razlike:

-   **Integriteta podatkov**: Sistemi umetne inteligence se močno zanašajo na podatke za učenje. [Zagotavljanje integritete teh podatkov je ključnega pomena, saj lahko napadalci manipulirajo s podatki, da vplivajo na vedenje umetne inteligence, kar je taktika, znana kot zastrupitev podatkov.
-   **Varnost modela**: Sam model odločanja umetne inteligence je lahko tarča. [Napadalci lahko poskušajo obratno inženirstvo modela ali izkoristijo njegove slabosti za sprejemanje napačnih ali škodljivih odločitev.
-   **Adversarialni napadi**: Sistemi umetne inteligence so lahko dovzetni za adversarialne napade, kjer majhne, pogosto nevidne spremembe vhodnih podatkov povzročijo napake ali napačne napovedi umetne inteligence.
-   **Varnost infrastrukture**: Čeprav se tradicionalna kibernetska varnost osredotoča na zaščito infrastrukture, imajo sistemi umetne inteligence dodatne plasti kompleksnosti, kot so storitve v oblaku ali specializirana strojna oprema, ki zahtevajo specifične varnostne ukrepe.
-   **Etična vprašanja**: Uporaba umetne inteligence v varnosti prinaša etična vprašanja, kot so pomisleki glede zasebnosti in možnost pristranskosti pri odločanju, ki jih je treba obravnavati v varnostni strategiji.

Na splošno zagotavljanje varnosti sistemov umetne inteligence zahteva drugačen pristop, ki upošteva edinstvene vidike tehnologije umetne inteligence, vključno z zaščito podatkov, modelov in procesov učenja umetne inteligence, hkrati pa obravnava etične posledice njene uporabe.

Varnost umetne inteligence in tradicionalna kibernetska varnost imata veliko skupnega, vendar se tudi razlikujeta zaradi edinstvenih značilnosti in zmogljivosti sistemov umetne inteligence. Tukaj je, kako se razlikujeta:

- **Kompleksnost groženj**: Sistemi umetne inteligence uvajajo nove plasti kompleksnosti v kibernetsko varnost. Tradicionalna kibernetska varnost se primarno ukvarja z grožnjami, kot so zlonamerna programska oprema, phishing napadi in vdori v omrežje. Sistemi umetne inteligence pa so lahko ranljivi za napade, kot so adversarialni napadi, zastrupitev podatkov in izogibanje modelom, ki ciljajo neposredno na algoritme strojnega učenja.

- **Površina napada**: Sistemi umetne inteligence imajo pogosto večjo površino napada v primerjavi s tradicionalnimi sistemi. To je zato, ker se ne zanašajo le na programsko opremo, temveč tudi na podatke in modele. Napadalci lahko ciljajo na podatke za učenje, manipulirajo z modeli ali izkoristijo ranljivosti v samih algoritmih.

- **Prilagodljivost groženj**: Sistemi umetne inteligence se lahko prilagajajo in učijo iz svojega okolja, kar jih lahko naredi bolj dovzetne za prilagodljive in razvijajoče se grožnje. Tradicionalni ukrepi kibernetske varnosti morda ne zadostujejo za obrambo pred napadi, ki se nenehno razvijajo glede na vedenje sistema umetne inteligence.

- **Razložljivost in interpretacija**: Razumevanje, zakaj je sistem umetne inteligence sprejel določeno odločitev, je pogosto bolj zahtevno v primerjavi s tradicionalnimi programskimi sistemi. Ta pomanjkanje razložljivosti in interpretacije lahko oteži učinkovito zaznavanje in ublažitev napadov na sisteme umetne inteligence.

- **Pomisleki glede zasebnosti podatkov**: Sistemi umetne inteligence se pogosto zanašajo na velike količine podatkov, kar lahko povzroči tveganja za zasebnost, če niso ustrezno obravnavani. Tradicionalni ukrepi kibernetske varnosti morda ne zadostujejo za obravnavo teh specifičnih pomislekov glede zasebnosti podatkov v sistemih umetne inteligence.

- **Regulativna skladnost**: Regulativno okolje za varnost umetne inteligence se še razvija, z nastajajočimi specifičnimi predpisi in standardi za obravnavo edinstvenih izzivov, ki jih predstavljajo sistemi umetne inteligence. Tradicionalni okviri kibernetske varnosti bodo morda morali biti razširjeni ali prilagojeni, da zagotovijo skladnost s temi novimi predpisi.

- **Etična vprašanja**: Varnost umetne inteligence vključuje ne le zaščito sistemov pred zlonamernimi napadi, temveč tudi zagotavljanje, da se sistemi umetne inteligence uporabljajo na etičen in odgovoren način. To vključuje vprašanja, kot so pravičnost, transparentnost in odgovornost, ki morda niso tako izrazita v tradicionalni kibernetski varnosti.

## Kako je varnost umetne inteligence podobna varnosti tradicionalnih IT sistemov?

Zagotavljanje varnosti sistemov umetne inteligence deli več temeljnih načel s tradicionalno kibernetsko varnostjo:

-   **Zaščita pred grožnjami**: Tako umetna inteligenca kot tradicionalni sistemi morajo biti zaščiteni pred nepooblaščenim dostopom, spreminjanjem podatkov in uničenjem ter drugimi pogostimi grožnjami.
-   **Upravljanje ranljivosti**: Številne ranljivosti, ki vplivajo na tradicionalne sisteme, kot so programske napake ali napačne konfiguracije, lahko vplivajo tudi na sisteme umetne inteligence.
-   **Varnost podatkov**: Zaščita obdelanih podatkov je ključna v obeh domenah za preprečevanje kršitev podatkov in zagotavljanje zaupnosti.
-   **Varnost dobavne verige**: Obe vrsti sistemov sta dovzetni za napade na dobavno verigo, kjer lahko ogrožena komponenta ogrozi varnost celotnega sistema.

Te podobnosti poudarjajo, da čeprav sistemi umetne inteligence prinašajo nove varnostne izzive, zahtevajo tudi uporabo uveljavljenih praks kibernetske varnosti za zagotavljanje robustne zaščite. Gre za kombinacijo uporabe tradicionalne varnostne modrosti in prilagajanja edinstvenim vidikom tehnologije umetne inteligence.

## Nadaljnje branje

- [Not with a Bug, But with a Sticker [Book] (oreilly.com)](https://www.oreilly.com/library/view/not-with-a/9781119883982/)
   
- [Intro to AI Security Part 1: AI Security 101 | by HarrietHacks | Medium](https://medium.com/@harrietfarlow/intro-to-ai-security-part-1-ai-security-101-b8662a9efe5)
   
- [Best practices for AI security risk management | Microsoft Security Blog](https://www.microsoft.com/en-us/security/blog/2021/12/09/best-practices-for-ai-security-risk-management/?WT.mc_id=academic-96948-sayoung)
   
- [OWASP AI Security and Privacy Guide | OWASP Foundation](https://owasp.org/www-project-ai-security-and-privacy-guide/)

---

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo storitve za prevajanje z umetno inteligenco [Co-op Translator](https://github.com/Azure/co-op-translator). Čeprav si prizadevamo za natančnost, vas prosimo, da upoštevate, da lahko avtomatizirani prevodi vsebujejo napake ali netočnosti. Izvirni dokument v njegovem maternem jeziku je treba obravnavati kot avtoritativni vir. Za ključne informacije priporočamo profesionalni človeški prevod. Ne prevzemamo odgovornosti za morebitna nesporazume ali napačne razlage, ki bi nastale zaradi uporabe tega prevoda.