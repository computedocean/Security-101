<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b6bb7175672298d1e2f73ba7e0006f95",
  "translation_date": "2025-09-03T21:34:29+00:00",
  "source_file": "8.2 AI security capabilities.md",
  "language_code": "ar"
}
-->
# قدرات أمان الذكاء الاصطناعي

[![شاهد الفيديو](../../translated_images/8-2_placeholder.bc988ce5dff1726a8b6f8c00b1250865ca23d02aa5cb11fb879ed1194702c99a.ar.png)](https://learn-video.azurefd.net/vod/player?id=e0a6f844-d884-4f76-99bd-4ce9f7f73d22)

## ما هي الأدوات والقدرات المتوفرة حاليًا لتأمين أنظمة الذكاء الاصطناعي؟

حاليًا، هناك العديد من الأدوات والقدرات المتاحة لتأمين أنظمة الذكاء الاصطناعي:

-   **Counterfit**: أداة مفتوحة المصدر لأتمتة اختبار أمان أنظمة الذكاء الاصطناعي، مصممة لمساعدة المؤسسات في إجراء تقييمات مخاطر أمان الذكاء الاصطناعي وضمان قوة خوارزمياتها.
-   **أدوات تعلم الآلة العدائية**: هذه الأدوات تقيم قوة نماذج تعلم الآلة ضد الهجمات العدائية، مما يساعد في تحديد الثغرات ومعالجتها.
-   **مجموعات أدوات أمان الذكاء الاصطناعي**: هناك مجموعات أدوات مفتوحة المصدر توفر موارد لتأمين أنظمة الذكاء الاصطناعي، بما في ذلك المكتبات والأطر لتنفيذ تدابير الأمان.
-   **منصات التعاون**: شراكات بين الشركات ومجتمعات الذكاء الاصطناعي لتطوير أدوات مثل ماسحات أمان مخصصة للذكاء الاصطناعي وغيرها لتأمين سلسلة توريد الذكاء الاصطناعي.

هذه الأدوات والقدرات جزء من مجال متنامٍ مخصص لتعزيز أمان أنظمة الذكاء الاصطناعي ضد مجموعة متنوعة من التهديدات. إنها تمثل مزيجًا من البحث والأدوات العملية والتعاون الصناعي لمعالجة التحديات الفريدة التي تطرحها تقنيات الذكاء الاصطناعي.

## ماذا عن فرق اختبار أمان الذكاء الاصطناعي؟ كيف تختلف عن فرق اختبار الأمان التقليدية؟

فرق اختبار أمان الذكاء الاصطناعي تختلف عن فرق اختبار الأمان التقليدية في عدة جوانب رئيسية:

-   **التركيز على أنظمة الذكاء الاصطناعي**: فرق اختبار أمان الذكاء الاصطناعي تستهدف الثغرات الفريدة لأنظمة الذكاء الاصطناعي، مثل نماذج تعلم الآلة وخطوط البيانات، بدلاً من البنية التحتية التقليدية لتكنولوجيا المعلومات.
-   **اختبار سلوك الذكاء الاصطناعي**: يتضمن ذلك اختبار كيفية استجابة أنظمة الذكاء الاصطناعي للمدخلات غير العادية أو غير المتوقعة، مما يمكن أن يكشف عن ثغرات قد يستغلها المهاجمون.
-   **استكشاف إخفاقات الذكاء الاصطناعي**: فرق اختبار أمان الذكاء الاصطناعي تنظر في الإخفاقات الخبيثة وغير الخبيثة، مع الأخذ في الاعتبار مجموعة أوسع من الشخصيات المحتملة والإخفاقات النظامية التي تتجاوز مجرد الاختراقات الأمنية.
-   **حقن التعليمات وإنشاء المحتوى**: يشمل ذلك اختبار الإخفاقات مثل حقن التعليمات، حيث يقوم المهاجمون بالتلاعب بأنظمة الذكاء الاصطناعي لإنتاج محتوى ضار أو غير موثوق.
-   **الذكاء الاصطناعي الأخلاقي والمسؤول**: جزء من ضمان الذكاء الاصطناعي المسؤول من خلال التصميم، للتأكد من أن أنظمة الذكاء الاصطناعي قوية ضد المحاولات لجعلها تتصرف بطرق غير مقصودة.

بشكل عام، فرق اختبار أمان الذكاء الاصطناعي هي ممارسة موسعة لا تغطي فقط البحث عن الثغرات الأمنية، بل تشمل أيضًا اختبار أنواع أخرى من الإخفاقات النظامية الخاصة بتقنيات الذكاء الاصطناعي. إنها جزء أساسي من تطوير أنظمة ذكاء اصطناعي أكثر أمانًا من خلال فهم وتخفيف المخاطر الجديدة المرتبطة بنشر الذكاء الاصطناعي.

## قراءة إضافية

 - [Microsoft AI Red Team building future of safer AI | Microsoft Security Blog](https://www.microsoft.com/en-us/security/blog/2023/08/07/microsoft-ai-red-team-building-future-of-safer-ai/?WT.mc_id=academic-96948-sayoung)
 - [Announcing Microsoft’s open automation framework to red team generative AI Systems | Microsoft Security Blog](https://www.microsoft.com/en-us/security/blog/2024/02/22/announcing-microsofts-open-automation-framework-to-red-team-generative-ai-systems/?WT.mc_id=academic-96948-sayoung)
 - [AI Security Tools: The Open-Source Toolkit | Wiz](https://www.wiz.io/academy/ai-security-tools)

---

**إخلاء المسؤولية**:  
تم ترجمة هذا المستند باستخدام خدمة الترجمة بالذكاء الاصطناعي [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى لتحقيق الدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو معلومات غير دقيقة. يجب اعتبار المستند الأصلي بلغته الأصلية المصدر الرسمي. للحصول على معلومات حاسمة، يُوصى بالاستعانة بترجمة بشرية احترافية. نحن غير مسؤولين عن أي سوء فهم أو تفسيرات خاطئة تنشأ عن استخدام هذه الترجمة.